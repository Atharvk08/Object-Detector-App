{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4aae9f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:2000/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "127.0.0.1 - - [14/Jun/2022 14:20:23] \"POST /predictObject HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image sending\n",
      "running1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "127.0.0.1 - - [14/Jun/2022 14:24:30] \"POST /predictObject HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image sending\n",
      "running1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "127.0.0.1 - - [14/Jun/2022 14:27:32] \"POST /predictObject HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image sending\n"
     ]
    }
   ],
   "source": [
    "from re import DEBUG\n",
    "from flask import Flask, jsonify, request ,render_template, send_file\n",
    "import pickle\n",
    "from PIL import Image, ImageDraw\n",
    "from torchvision.transforms import functional as func\n",
    "import torch\n",
    "import base64\n",
    "import io\n",
    "import re\n",
    "import json\n",
    "from base64 import decodestring\n",
    "import numpy as np\n",
    "\n",
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "app=Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route('/predictObject',methods=[\"POST\"])\n",
    "def predict():\n",
    "    imagestr=\"\"\n",
    "#     for file in list(request.files):\n",
    "#         imagestr=request.files[file]\n",
    "#     print(request.body())\n",
    "    data=None\n",
    "    content_type = request.headers.get('Content-Type')\n",
    "    if (content_type == 'application/json; charset=utf-8'):\n",
    "#         try:\n",
    "        print(\"running1\")\n",
    "#         print(request.json)\n",
    "        data = json.loads(request.data.decode(\"utf-8\") )\n",
    "        print(data)\n",
    "        print(\"running2\")\n",
    "\n",
    "    #     data = request.json\n",
    "    #     print(data)\n",
    "        imagestr = data['imagefile']\n",
    "    # process Image\n",
    "    #     img = Image.fromstring('RGB',(width,height),decodestring(imagestr))\n",
    "    #     print(imagestr)\n",
    "    #     imgObj = io.BytesIO(base64.decodebytes(bytes(imagestr,\"ascii\")))\n",
    "    #     print(type(imgObj))\n",
    "    #     img = Image.open(imgObj)\n",
    "        print(\"Image received\")\n",
    "        imagestr = re.sub('^data:image/.+;base64,', '', imagestr)\n",
    "        decoded = base64.b64decode(imagestr)\n",
    "        img = Image.open(io.BytesIO(decoded))\n",
    "    #     img = preprocess_image(img, target_size=(224, 224))\n",
    "\n",
    "    #     img = Image.open((base64.b64decode(imagestr)))\n",
    "    #     img=Image.open(imagePath)\n",
    "        # Run the model on GPU if it is available\n",
    "\n",
    "        image = func.to_tensor(img)\n",
    "        # image=torch.tensor(image)\n",
    "        c, h, w = image.shape\n",
    "    #     img.show()\n",
    "        # Perform inference\n",
    "        preds = model([image])[0]\n",
    "        labels = preds[\"labels\"].cpu().detach().numpy()\n",
    "        scores = preds[\"scores\"].cpu().detach().numpy()\n",
    "        boxes = preds[\"boxes\"].cpu().detach().numpy()\n",
    "\n",
    "\n",
    "        img1 = ImageDraw.Draw(img) \n",
    "        result={}\n",
    "        for label, score, box in zip(labels, scores, boxes):\n",
    "            # Convert to [top-left-x, top-left-y, width, height]\n",
    "            # in relative coordinates in [0, 1] x [0, 1]\n",
    "            if score>= .9 :\n",
    "                x1, y1, x2, y2 = box\n",
    "    #             rel_box = [x1 / w, y1 / h, (x2r - x1) / w, (y2 - y1) / h]\n",
    "                rel_box=[x1, y1, x2, y2]\n",
    "                name=label if len(COCO_INSTANCE_CATEGORY_NAMES)<label else COCO_INSTANCE_CATEGORY_NAMES[label]\n",
    "                #result[label]=[name,score]\n",
    "                img1.rectangle(rel_box,  outline =\"blue\")\n",
    "    #             img=img1\n",
    "        img.show()\n",
    "        # return send_file(imagePath, mimetype='image/jpg')     \n",
    "        imgByteArr = io.BytesIO()\n",
    "        img = np.array(img, dtype=np.uint8)\n",
    "        img=Image.fromarray(img)\n",
    "        img.save(imgByteArr, format='jpeg')\n",
    "        imgByteArr = imgByteArr.getvalue()\n",
    "        print(\"Image sending\")\n",
    "        return str(jsonify({\"resultant_image\" : str(base64.b64encode(imgByteArr))}))\n",
    "#         except Exception as e:\n",
    "#             print(e)\n",
    "#             return \"Error\"\n",
    "        \n",
    "    else:\n",
    "        print('Content-Type not supported!'+content_type)\n",
    "        return 'Content-Type not supported!'\n",
    "\n",
    "# http://10.0.2.2:8080/\n",
    "if __name__ == '__main__':\n",
    "    with open('mlmodel.pickle', 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "    app.run(port=2000,debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fb3886d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:2000/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running1\n",
      "running2\n",
      "Image received\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [11/Jul/2022 19:06:10] \"POST /predictObject HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image sending\n",
      "running1\n",
      "running2\n",
      "Image received\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [11/Jul/2022 19:07:35] \"POST /predictObject HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image sending\n"
     ]
    }
   ],
   "source": [
    "from re import DEBUG\n",
    "from flask import Flask, jsonify, request ,render_template, send_file\n",
    "import pickle\n",
    "from PIL import Image, ImageDraw , ImageFont\n",
    "from torchvision.transforms import functional as func\n",
    "import torch\n",
    "import base64\n",
    "import io\n",
    "import re\n",
    "import json\n",
    "from base64 import decodestring\n",
    "import numpy as np\n",
    "\n",
    "font_family = \"arial.ttf\"\n",
    "fontsize=30\n",
    "font = ImageFont.truetype(font_family, fontsize)\n",
    "\n",
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "app=Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route('/predictObject',methods=[\"POST\"])\n",
    "def predict():\n",
    "    imagestr=\"\"\n",
    "#     for file in list(request.files):\n",
    "#         imagestr=request.files[file]\n",
    "#     print(request.body())\n",
    "    data=None\n",
    "    content_type = request.headers.get('Content-Type')\n",
    "    if (content_type == 'application/json; charset=utf-8'):\n",
    "#         try:\n",
    "        print(\"running1\")\n",
    "#         print(request.json)\n",
    "        data = json.loads(request.data.decode(\"utf-8\") )\n",
    "        print(\"running2\")\n",
    "\n",
    "    #     data = request.json\n",
    "    #     print(data)\n",
    "        imagestr = data['imagefile']\n",
    "    # process Image\n",
    "    #     img = Image.fromstring('RGB',(width,height),decodestring(imagestr))\n",
    "    #     print(imagestr)\n",
    "    #     imgObj = io.BytesIO(base64.decodebytes(bytes(imagestr,\"ascii\")))\n",
    "    #     print(type(imgObj))\n",
    "    #     img = Image.open(imgObj)\n",
    "        print(\"Image received\")\n",
    "        imagestr = re.sub('^data:image/.+;base64,', '', imagestr)\n",
    "        decoded = base64.b64decode(imagestr)\n",
    "        img = Image.open(io.BytesIO(decoded))\n",
    "    #     img = preprocess_image(img, target_size=(224, 224))\n",
    "\n",
    "    #     img = Image.open((base64.b64decode(imagestr)))\n",
    "    #     img=Image.open(imagePath)\n",
    "        # Run the model on GPU if it is available\n",
    "        img = img.resize((round(img.size[0]*0.5), round(img.size[1]*0.5)))\n",
    "        \n",
    "        image = func.to_tensor(img)\n",
    "        # image=torch.tensor(image)\n",
    "        c, h, w = image.shape\n",
    "    #     img.show()\n",
    "        # Perform inference\n",
    "        preds = model([image])[0]\n",
    "        labels = preds[\"labels\"].cpu().detach().numpy()\n",
    "        scores = preds[\"scores\"].cpu().detach().numpy()\n",
    "        boxes = preds[\"boxes\"].cpu().detach().numpy()\n",
    "\n",
    "        img1 = ImageDraw.Draw(img) \n",
    "\n",
    "        result={}\n",
    "        for label, score, box in zip(labels, scores, boxes):\n",
    "            # Convert to [top-left-x, top-left-y, width, height]\n",
    "            # in relative coordinates in [0, 1] x [0, 1]\n",
    "            if score>= .9 :\n",
    "                x1, y1, x2, y2 = box\n",
    "    #             rel_box = [x1 / w, y1 / h, (x2r - x1) / w, (y2 - y1) / h]\n",
    "                rel_box=[x1, y1, x2, y2]\n",
    "                name=label if len(COCO_INSTANCE_CATEGORY_NAMES)<label else COCO_INSTANCE_CATEGORY_NAMES[label]\n",
    "                #result[label]=[name,score]\n",
    "                img1.rectangle(rel_box,  outline =\"blue\",width=7 )\n",
    "                img1.multiline_text((x1, y1), \"{} : {:.2f}\".format(name,score) ,font=font,  fill=(255, 255, 255))\n",
    "    #             img=img1\n",
    "        img.show()\n",
    "        # return send_file(imagePath, mimetype='image/jpg')     \n",
    "        imgByteArr = io.BytesIO()\n",
    "        img = np.array(img, dtype=np.uint8)\n",
    "        img=Image.fromarray(img)\n",
    "        img.save(imgByteArr, format='jpeg')\n",
    "        imgByteArr = imgByteArr.getvalue()\n",
    "        print(\"Image sending\")\n",
    "        s= str(json.dumps({\"resultant_image\" : str(base64.b64encode(imgByteArr))}))\n",
    "#         print(s)\n",
    "        return s\n",
    "#         except Exception as e:\n",
    "#             print(e)\n",
    "#             return \"Error\"\n",
    "        \n",
    "    else:\n",
    "        print('Content-Type not supported!'+content_type)\n",
    "        return 'Content-Type not supported!'\n",
    "\n",
    "# http://10.0.2.2:8080/\n",
    "if __name__ == '__main__':\n",
    "    with open('mlmodel.pickle', 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "    app.run(port=2000,debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71ac1c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:2000/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running1\n",
      "running2\n",
      "Image received\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Jun/2022 19:38:40] \"POST /predictObject HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image sending\n"
     ]
    }
   ],
   "source": [
    "from re import DEBUG\n",
    "from flask import Flask, jsonify, request ,render_template, send_file\n",
    "import pickle\n",
    "from PIL import Image, ImageDraw , ImageFont\n",
    "from torchvision.transforms import functional as func\n",
    "import torch\n",
    "import base64\n",
    "import io\n",
    "import re\n",
    "import json\n",
    "from base64 import decodestring\n",
    "import numpy as np\n",
    "\n",
    "font_family = \"arial.ttf\"\n",
    "fontsize=30\n",
    "font = ImageFont.truetype(font_family, fontsize)\n",
    "\n",
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "app=Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route('/predictObject',methods=[\"POST\"])\n",
    "def predict():\n",
    "    imagestr=\"\"\n",
    "#     for file in list(request.files):\n",
    "#         imagestr=request.files[file]\n",
    "#     print(request.body())\n",
    "    data=None\n",
    "    content_type = request.headers.get('Content-Type')\n",
    "    if (content_type == 'application/json; charset=utf-8'):\n",
    "#         try:\n",
    "        print(\"running1\")\n",
    "#         print(request.json)\n",
    "        data = json.loads(request.data.decode(\"utf-8\") )\n",
    "        print(\"running2\")\n",
    "\n",
    "    #     data = request.json\n",
    "    #     print(data)\n",
    "        imagestr = data['imagefile']\n",
    "    # process Image\n",
    "    #     img = Image.fromstring('RGB',(width,height),decodestring(imagestr))\n",
    "    #     print(imagestr)\n",
    "    #     imgObj = io.BytesIO(base64.decodebytes(bytes(imagestr,\"ascii\")))\n",
    "    #     print(type(imgObj))\n",
    "    #     img = Image.open(imgObj)\n",
    "        print(\"Image received\")\n",
    "        imagestr = re.sub('^data:image/.+;base64,', '', imagestr)\n",
    "        decoded = base64.b64decode(imagestr)\n",
    "        img = Image.open(io.BytesIO(decoded))\n",
    "    #     img = preprocess_image(img, target_size=(224, 224))\n",
    "\n",
    "    #     img = Image.open((base64.b64decode(imagestr)))\n",
    "    #     img=Image.open(imagePath)\n",
    "        # Run the model on GPU if it is available\n",
    "        img = img.resize((round(img.size[0]*0.5), round(img.size[1]*0.5)))\n",
    "        \n",
    "        image = func.to_tensor(img)\n",
    "        # image=torch.tensor(image)\n",
    "        c, h, w = image.shape\n",
    "    #     img.show()\n",
    "        # Perform inference\n",
    "        preds = model([image])[0]\n",
    "        labels = preds[\"labels\"].cpu().detach().numpy()\n",
    "        scores = preds[\"scores\"].cpu().detach().numpy()\n",
    "        boxes = preds[\"boxes\"].cpu().detach().numpy()\n",
    "\n",
    "        img1 = ImageDraw.Draw(img) \n",
    "\n",
    "        result={}\n",
    "        for label, score, box in zip(labels, scores, boxes):\n",
    "            # Convert to [top-left-x, top-left-y, width, height]\n",
    "            # in relative coordinates in [0, 1] x [0, 1]\n",
    "            if score>= .9 :\n",
    "                x1, y1, x2, y2 = box\n",
    "    #             rel_box = [x1 / w, y1 / h, (x2r - x1) / w, (y2 - y1) / h]\n",
    "                rel_box=[x1, y1, x2, y2]\n",
    "                name=label if len(COCO_INSTANCE_CATEGORY_NAMES)<label else COCO_INSTANCE_CATEGORY_NAMES[label]\n",
    "                #result[label]=[name,score]\n",
    "                img1.rectangle(rel_box,  outline =\"blue\",width=7 )\n",
    "                img1.multiline_text((x1, y1), \"{} : {:.2f}\".format(name,score) ,font=font,  fill=(255, 255, 255))\n",
    "    #             img=img1\n",
    "        img.show()\n",
    "        # return send_file(imagePath, mimetype='image/jpg')     \n",
    "        imgByteArr = io.BytesIO()\n",
    "        img = np.array(img, dtype=np.uint8)\n",
    "        img=Image.fromarray(img)\n",
    "        img.save(imgByteArr, format='jpeg')\n",
    "        imgByteArr = imgByteArr.getvalue()\n",
    "        print(\"Image sending\")\n",
    "        s= str(json.dumps({\"resultant_image\" : str(base64.b64encode(imgByteArr))}))\n",
    "#         print(s)\n",
    "        return s\n",
    "#         except Exception as e:\n",
    "#             print(e)\n",
    "#             return \"Error\"\n",
    "        \n",
    "    else:\n",
    "        print('Content-Type not supported!'+content_type)\n",
    "        return 'Content-Type not supported!'\n",
    "\n",
    "# http://10.0.2.2:8080/\n",
    "if __name__ == '__main__':\n",
    "    with open('mlmodel.pickle', 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "    app.run(port=2000,debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bb67e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
